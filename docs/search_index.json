[
["index.html", "R para análise de dados Apresentação Objetivos Estrutura Requisitos Programa", " R para análise de dados Ítalo Cegatta Apresentação Este site reúne os materiais utilizados no curso prático de análise de dados com a linguagem de programação R. O objetivo do curso é fornecer aos participantes, sem conhecimento prévio de programação, as habilidades necessárias para iniciar uma análise de dadis utilizando o R. Objetivos Após concluir este material, os alunos irão: Estar familiarizados com o ambiente de programação do R e RStudio Ser capaz de visualizar seus dados Ser capaz de executar etapas básicas de preparação de dados Ser capaz de executar a transformação de dados e resumos Ser capaz de calcular estatísticas básicas Estrutura O curso é composto de 3 módulos, cada um com uma carga horária de 16 horas. Este material é utilizado durante o curso e todos os códigos e exercícios são executados pelos alunos. Requisitos Para realização dos curso, é necessário um computador com as versões mais recentes dos softwares R e RStudio instalados. Software R Software RStudio Pacotes install.packages(c(\"tidyverse\", \"readxl\", \"broom\", \"car\", \"agricolae\")) Bases de dados Programa Módulo I Dia 1 Introdução à linguagem R e Processamento Básico de dados Linguagem R e RStudio Conceituações básicas do R e sua área de trabalho Pacotes e funções básicas Manipulação de dados Dia 2 Visualização de dados e estatística experimental Processamento e análise gráfica de dados Regressão linear ANOVA Teste de Tukey Módulo II Dia 1 Elementos básicos da linguagem R Tipos de elementos e objetos Indexação Strings, fatores e datas Joins Dia 2 Organização de dados, loops Tidy data Iteração (loops, purrr) Módulo III Dia 1 Processamento geoespacial e Web scraping Raster Vetor Mapas Web scraping Dia 2 Criação de pacotes e aplicativos interativos Funções Pacotes Shiny "],
["sobre-o-r.html", "Sobre o R Download do R e RStudio", " Sobre o R Se dedicar para aprender uma nova linguagem de programação não é uma tarefa fácil. Principalmente para quem não tem um background de lógica de programação. O R é um software open-source mantido por um grupo de voluntários de vários países, o R-core team. No site oficial do projeto a primeira descrição sobre ele é a seguinte: O R é uma linguagem e ambiente para computação estatística e gráficos. Esse grupo mantem o sistema base que possibilita a interação com a linguagem R para computação numérica, manipulação de dados, gráficos e uma variedade de outras tarefas. No R, tudo o que acontece é o resultado de uma função. Eu, você e tantos outros usuários podemos desenvolver funções para facilitar a nossa vida, posteriormente organizá-las em pacotes (ou packages) e depois disponibilizar para todo o mundo. O projeto do R teve início com Ross Ihaka e Robert Gentleman nos anos 90 a partir de uma implementação da linguagem S, que foi desenvolvida anos antes por um grupo de pesquisadores liderados por John Chambers no Bell Laboratories. Desde então, o R tem crescido em um ritmo absurdo e pode ser considerado o principal software livre para programação estatística e um dos mais usados no mundo. Sobre as potencialidades do R, no contexto de análise de dados, não há restrições. Em comparação com outras linguagem e softwares podemos ter diferença entre velocidade de processamento, suporte e disponibilidade de bibliotecas específicas, mas há um jargão antigo na comunidade R diz: pergunta certa sobre uma tarefa no R não é se podemos fazer, mas sim como podemos fazer. Download do R e RStudio O download do software R pode ser feito no site do CRAN. Após a instalação você já está apto para iniciar sua análise. Para trabalharmos em um ambiente com maiores funcionalidade, podemos optar por utilizar um ambiente de desenvolvimento integrado ao R. O RStudio é um dos mais utilizados e possui diversas funcionalidades que facilitam nossa vida durante uma análise. Faça o download do RStudio nesse link. Note que é preciso instlar o R antes, para conseguir instalar o Rstudio normalmente. "],
["manipulacao-de-dados.html", "Manipulação de dados Warm-Up Sobre o Tidyverse", " Manipulação de dados Warm-Up Conhecendo os dados Vamos começar importando os dados do arquivo filmes_imdb.csv. Para indicar que o arquivo está dentro de uma pasta, é preciso utilizar a barra /, library(tidyverse) df &lt;- read_csv2(&quot;input/filmes_imdb.csv&quot;) df Primeiro vamos fazer um histograma para poder ver a distribuição da variável nota. ggplot(data = df, aes(x = nota)) + geom_histogram() Agora, vamos ver a relação entre o valor_captado e o publico dos filmes. ggplot(data = df, aes(x = orcamento, y = faturamento)) + geom_point() ggplot(df, aes(orcamento, faturamento)) + geom_point() + geom_smooth() Qual o lucro médio dos filmes? Nosso objetivo agora é calcular o lucro médio dos filmes. Primeiro vamos criar uma coluna e calcular o lucro de cada filme. df2 &lt;- mutate(df, lucro = faturamento - orcamento) df2 Vamos isolar os valores de lucro e colocar em um objeto e em seguida calcular a média. vec_lucro &lt;- pull(df2, lucro) mean(vec_lucro) Vamos refazer os 2 primeiros passos unindo os comandos em um só. vec_lucro &lt;- pull(mutate(df, lucro = faturamento - orcamento)) mean(vec_lucro) Seguindo a mesma ideia, podemos unificar todos os comandos em uma única chamada. mean(pull(mutate(df, lucro = faturamento - orcamento), lucro)) Agora utilizando um operador especial chamado pipe, vamos executar as mesmas funções, porém de forma organizada e de fácil interpretação. df %&gt;% mutate(lucro = faturamento - orcamento) %&gt;% pull(lucro) %&gt;% mean() Sobre o Tidyverse Neste curso utilizaremos como referência os pacotes vinculados ao tidyverse, grupo de funções que utilizam a mesma filosofia de programação e foram desenvolvidos para atuarem em conjunto. O tidyverse é mantido por um time de desenvolvedores do RStudio e liderado pelo seu idealizador Hadley Wickham. Há diversas funções disponíveis nos pacotes do tidyverse que tem um equivalente direto nos pacotes base do R, mas com uma implementação mais moderna e consistente que facilita a estruturação do código. No decorrer do curso vamos ter vários exemplos desse comparativo. A manipulação de dados é, na maioria das vezes, realizado com data.frames e por isso iremos ver as principais funções que lidam com essa estrutura de forma rápida e prática. O pacote dplyr é hoje um dos pacotes mais utilizados para esta finalidade. Ele disponibiliza diversas funções que são “equivalentes” às funções básicas do R, mas como melhorias que nos poupam tempo e deixam o código muito mais fácil de interpretar. Como exemplo, vamos realizar uma análise exploratória dos dados de um inventário na floresta amazônica. library(tidyverse) library(readxl) inv_amazonia &lt;- read_excel(&quot;input/inv_amazonia.xlsx&quot;) inv_amazonia Filter Com a função filter() é possível selecionar linhas específicas, de acordo com o fator que se deseja. Podem ser usados um ou vários fatores de seleção. filter(inv_amazonia, cap &gt; 300) filter(inv_amazonia, cap &gt; 300 &amp; qf &gt; 1) filter(inv_amazonia, cap &gt; 300 | hcom &gt; 15) filter(inv_amazonia, especie == &quot;IPE&quot;) filter(inv_amazonia, especie %in% c(&quot;COPAIBA&quot;, &quot;IPE&quot;)) Arrange Para ordenar as colunas, podemos usar a função arrange(). A hierarquia é dada pela sequência dos fatores que são adicionados como argumentos da função. arrange(inv_amazonia, cap) arrange(inv_amazonia, -cap) Select A função select() auxilia-nos na seleção de variáveis (colunas). select(inv_amazonia, especie, cap) select(inv_amazonia, especie:cap) select(inv_amazonia, -(familia:comercial)) Mutate Para criar novas variáveis, podemos usar a função mutate(). Um diferencial dessa função em relação à função base do R, é que podemos utilizar variáveis criadas dentro do próprio comando. mutate( inv_amazonia, dap = cap / pi, secao = pi * dap^2 / 4 ) Note que se quisermos utilizar os dados calculados no futuro, temos de salvar em um objeto. No caso, vamos salvar no mesmo objeto inv_amazonia2 de forma que ele será atualizado com as novas colunas. inv_amazonia2 &lt;- mutate( inv_amazonia, dap = cap / pi ) Summarise A função summarise nos permite resumir dados. Também é possível resumir dados em função de vários fatores com o group_by. summarise(inv_amazonia2, dap_medio = mean(dap)) summarise(inv_amazonia2, hcom_medio = mean(hcom)) summarise(inv_amazonia2, hcom_medio = mean(hcom, na.rm = TRUE)) inv_amazonia_by_esp &lt;- group_by(inv_amazonia2, especie) summarise(inv_amazonia_by_esp, dap_medio = mean(dap)) inv_amazonia_by_esp &lt;- group_by(inv_amazonia2, especie) resumo_esp &lt;- summarise( inv_amazonia_by_esp, n = n(), dap_medio = mean(dap, na.rm = TRUE), hcom_medio = mean(hcom, na.rm = TRUE) ) resumo_esp filter(resumo_esp, dap_medio &gt; 50) Operador %&gt;% O pacote dplyr foi desenhado para trabalhar em conjunto que o operador em cadeia %&gt;%. O que esse operador faz é aplicar o que está no LHS no primeiro parâmetro da função do RHS. Podemos também direcionar o local onde o conteúdo do LHS será aplicado informando um . como argumento. inv_amazonia2 %&gt;% group_by(especie) %&gt;% summarise( n = n(), dap_medio = mean(dap, na.rm = TRUE), hcom_medio = mean(hcom, na.rm = TRUE) ) %&gt;% filter(dap_medio &gt; 50) inv_amazonia %&gt;% filter(comercial == &quot;Sim&quot;) %&gt;% select(especie, cap) %&gt;% arrange(desc(cap)) %&gt;% slice(1:5) Gráficos rápidos inv_amazonia2 %&gt;% group_by(especie) %&gt;% summarise(dap_medio = mean(dap, na.rm = TRUE)) %&gt;% arrange(desc(dap_medio)) %&gt;% slice(1:20) %&gt;% ggplot(aes(especie, dap_medio)) + geom_col() + coord_flip() + theme_bw() inv_amazonia2 %&gt;% group_by(parcela) %&gt;% summarise(n = n()) %&gt;% arrange(desc(n)) %&gt;% ggplot(aes(factor(parcela), n)) + geom_col() + theme_bw() inv_amazonia2 %&gt;% ggplot(aes(dap, hcom)) + geom_point() + theme_bw() inv_amazonia2 %&gt;% ggplot(aes(dap, hcom, color = comercial)) + geom_point() + geom_smooth() + theme_bw() "],
["visualizacao.html", "Visualização Conceitos básicos Layers Os dados A camada de geometria A camada de estatísticas Edições de eixos Aesthetics Grupos Geometrias Escalas scale_x|y_continuous Escalas de cor Facets", " Visualização O ggplot2é o pacote mais utilizado para criação de gráficos no R. Ele implementa a Gramática dos Gráficos proposta por Leland Wilkinson em seu livro The Grammar of Graphics. A ideia é que há uma gramática racional e computacional para a composição de gráficos estatísticos. Ao controlar a gramática, você pode gerar um grande conjunto de gráficos cuidadosamente construídos a partir de um conjunto relativamente pequeno de operações. Existem muitos materiais e cursos sobre como criar gráficos com o ggplot2. Basta um simples google sobre o assunto ou problema que você tem e rapidamente vai aparecer uma pergunta semelhante e várias respostas assunto. Como padrão, a documentação do pacote pode ser consultada, bem como diversos livros sobre o assunto. Recomendo o site do pacotes ggplot2 e o livro do autor Conceitos básicos Existem alguns conceitos básicos em torno desde universo de gráficos. Em primeiro lugar, os gráficos são construídos em camadas (layers). Cada componente do gráfico, a partir dos dados fornecidos, está amarrado ao sistema de coordenadas e este por sua vez, está condicionado aos resumos estatísticos, rótulos e escalas. Portanto, gráficos expressos são construídos com poucos comandos, mas com definições padrões. Para criar gráficos personalizados e de maior qualidade é preciso adicionar algumas funções… mas fique tranquilo, dificilmente vai passar de 7 camadas. As propriedades gráficas que codificam os dados são dimensões tratadas como aesthetic no ggplot2, destacando: x y size shape color fill Os elementos gráficos são as geometrias, como: point line segment bar/col text area hitogram density Você também vai querer adicionar estatísticas que resumem seus dados, e o pacote possibilita algumas delas: smooth mean/median function As dimensões (aesthetic), geometrias e resumos estatísticos constituem as mais importantes camadas de gráfico, mas há uma série de outras características que você vai querer ajustar. As mais comuns são: Eixo x ou y em escala logarítmica Paletas de cores personalizadas Formas de pontos personalizado, ou tipos de linha As seções seguintes são dedicadas a alguns destes elementos básicos ggplot2. Layers Iremos criar gráficos em camadas. A estratificação de elementos é talvez o aspecto mais poderoso do ggplot2. Isso significa que gráficos relativamente complexos são construídos com pequenas peças, que você pode adicionar ou remover de forma iterativa. Os dados O primeiro argumento da função ggplot() é um data.frame, e seu segundo argumento é aes(). Você nunca vai usar aes() em qualquer outro contexto, exceto dentro de outras funções do ggplot2, por isso talvez seja melhor não pensar em aes() como função individual, mas sim como uma forma especial de definir as dimensões dos gráficos. library(tidyverse) library(readxl) inv &lt;- read_excel(&quot;input/TUME_134_2016.xlsx&quot;) ggplot(inv, aes(x = CAP_cm, y = H_m)) Veja que os dados e as dimensões dos dados já foram informados, entretanto não nada no gráfico criado por não temos uma geometria definida. Cada layer tem uma base de dados. Você pode indicar os dados na função principal ggplot() ou nos layers específicos. O mesmo ocorre para a definição das dimensões com a função aes(). A camada de geometria O passo seguinte, depois de definir os dados e as dimensões, é adicionar a geometrias. Iremos discutir geometrias em mais detalhe abaixo, mas por agora, vamos adicionar a mais simples de todas: os pontos. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_point() Cada camada é feita por uma função. Algumas não precisarão de argumentos pois será utilizado o default. No exemplo anterior, fizemos um gráfico e adicionamos a camada de ponto geom_point(), por padrão, serão mostrados pontos pretos e sólidos de tamanho 1. Caso você queira alterar o formato do ponto, basta especificar no argumento indicado. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_point(shape = 2) Ou, se quiséssemos usar pontos vermelhos e maiores, poderíamos definir: ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_point(color = &quot;red&quot;, size = 3) Como padrão, o ggplot2 cria um fundo cinza e linhas de grades brancas. Tem uma explicação plausível para isso e na maioria das vezes é bem útil, mas de forma geral não estamos acostumados a esse tema e isso pode incomodar. Mas fique tranquilo, isso é perfeitamente ajustável, vamos ver a seguir como fazê-lo. Outro padrão é o nome dos eixos. Ele é correspondente à variável indicada, mas também pode ser alterado utilizando a função labs. Finalmente, note que nós não precisamos dizer em geom_point() quais são as dimensões do gráfico. Já fizemos isso na função principal. Os layer herdam essas definições da função principal e por isso não precisamos ficar redefinindo a todo momento. A camada de estatísticas Adicionar uma linha de tendência uma suavização é muito simples, veja o exemplo. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_smooth(method = &quot;lm&quot;) Nesse gráfico, foi ajustado uma regressão linear com um intervalo de confiança de 95%. Uma coisa importante a entender é que não é necessário incluir os pontos, podemos apresentar somente a linha de tendência. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_smooth(method = &quot;lm&quot;) Edições de eixos Podemos alterar o nome dos eixos e ainda adicionar título, subtítulo e fonte ao gráfico. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_smooth(method = &quot;lm&quot;) + labs( title = &quot;TUME 134&quot;, subtitle = &quot;Faz. Areão&quot;, caption = &quot;Projeto TUME&quot;, x = &quot;CAP (cm)&quot;, y = &quot;Altura (m)&quot; ) + theme_bw() Aesthetics No ggplot2, aesthetic são os elementos gráficos que representam as dimensões dos dados, e que são definidos com aes(). Em certa medida, a dimensão que você precisa para definir depende das geometrias que você deseja utilizar. Por exemplo, segmentos de linha tem propriedades geométricas diferentes de pontos. Mas de maneira geral, essa padronização não é problemática. x: localização do eixo-X. y: localização do eixo y. color: A cor das linhas, pontos, e as fronteiras externas das geometrias (polígonos, barras, etc.). fill : A cor de preenchimento das geometrias. size: O tamanho dos pontos. shape: Específico para pontos, define a forma dele. linetype: Específico para linhas, define o tipo de linha, caminho, ou borda de uma geometria. alpha: Isto define a opacidade de qualquer propriedade geométrica. É mais utilizada quando temos sobreposição de pontos ou linhas e queremos enxergar o que está por de trás. xend, yend: Você vai usá-los raramente, quando criar um segmento de linha, ou seta. O início do segmento de linha será localizado o x e y, e a extremidade do segmento de linha será definida em xend, yend. Se aplicarmos a dimensão de cor em função da variável Cod, vamos notar que o ggplot2 entendeu que se trata de números e por isso adicionou uma escala contínua de cor na legenda. Não está certo, mas é o default. ggplot(inv, aes(x = CAP_cm, y = H_m, color = Cod)) + geom_point() O ggplot2 gerou automaticamente uma paleta de cores para os dados e criou uma legenda. Tal como acontece com tudo, a paleta de cores também é ajustável, o que será discutido em mais detalhe abaixo. O padrão de cores do ggplot2 é bastante inteligente. Cada cor é equidistante em torno de um círculo de cor HSL, e têm igual luminância. A ideia é que nenhuma categoria tenha maior destaque que outra, em contrapartida ela pode ser um problema para leitores daltônicos. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_point(color = &quot;red&quot;) Neste momento você pode notar a diferença de indicar a cor fora do aes() não gera legenda e se aplica a todos os pontos. Quando a cor representa uma dimensão dos nossos dados, seja uma escala discreta ou contínua, ela deve ser indicada dentro da função aes() em conjunto com a variável que definirá a dimensão. Grupos Vamos criar um gráfico com uma linha de tendência por ano. O parâmetro se = FALSE é para retirar o intervalo de confiança da linha de tendência e facilita a visualização. ggplot(inv, aes(x = CAP_cm, y = H_m, color = Esp)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) Como a dimensão cor foi definida na função principal, todos layers herdaram essa informação. Mas e se quisermos um gráfico com pontos coloridos, mas só uma linha de tendência? Simples, vamos dar a dimensão de cor somente para o layer de pontos. ggplot(inv, aes(x = CAP_cm, y = H_m)) + geom_point(aes(color = Esp)) + geom_smooth(method = &quot;lm&quot;) É importante lembrar que não é só a dimensão de cor que gera sub-agrupamentos no gráfico. Se utilizarmos a forma para diferenciar a variável, essa definição também será herdade nos layers subsequentes. ggplot(inv, aes(x = CAP_cm, y = H_m, shape = Esp)) + geom_point() A criação de gráficos com cores é uma atividade comum em muitas situações. Podemos definir se um gráfico será colorido de duas formas, o preenchimento interno da geometria ou a linha externa. Para o primeiro, utilizamos o argumento fill = &lt;variável&gt;e para o segundo color = &lt;variável&gt;. Note que as variáveis podem ser contínuas ou discretas para ambos os casos. resumo_clone &lt;- inv %&gt;% group_by(Esp) %&gt;% summarise( H_m = mean(H_m, na.rm = TRUE), CAP_cm = mean(CAP_cm, na.rm = TRUE), n_arv = n(), n_falha = sum(ifelse(Cod == 1, 1, 0), na.rm = TRUE), p_alha = (n_falha / n_arv) * 100 ) ggplot(resumo_clone, aes(Esp, CAP_cm)) + geom_col() Se quisermos colorir as barras, o primeiro instinto seria provavelmente para definir color = Esp. Mas este argumento considera apenas o contorno das figuras bidimensionais. ggplot(resumo_clone, aes(Esp, CAP_cm, color = Esp)) + geom_col() O preenchimento é feito utilizando o argumento fill = Esp. ggplot(resumo_clone, aes(Esp, CAP_cm, fill = Esp)) + geom_col() Geometrias Até o momento, nós usamos as seguintes geometrias: geom_point() geom_smooth() geom_col() Todas as geometrias começam com geom_*, esta é a lista completa das geometrias disponível pelo ggplot2. apropos(&quot;^geom_&quot;) Esta é uma lista bastante extensa, e não iremos ver todo seu conteúdo hoje. Mas podemos iremos exemplificar alguns casos. Histograma e Densidade O histograma é um gráfico univariado bastante comum no meio científico. Sua principal função é apresentar a distribuição de frequências dos dados. ggplot(inv, aes(CAP_cm)) + geom_histogram() Também é possível considerar a distribuição dos Clones de maneira independente e adicionar uma transparência às barras. ggplot(inv, aes(CAP_cm, fill = Esp)) + geom_histogram(position = &quot;identity&quot;, alpha = 0.5) Densidade Visualizar a distribuição de frequências também é um recurso muito interessante para entender os nossos dados. Podemos fazê-lo através de um histograma eu de gráfico de densidade de frequências. ggplot(inv, aes(H_m)) + geom_density() Podemos identificar a distribuição do Esp através de cores. ggplot(inv, aes(H_m, fill = Esp)) + geom_density() Entretanto o padrão da função geom_density() é usar position = \"identity\". Isso significa que pode haver (como de fato acontece) sobreposição das curvas. Uma alternativa rápida é colocar opacidade ao preenchimento para poder ver através das curvas. ggplot(inv, aes(H_m, fill = Esp, color = Esp)) + geom_density(alpha = 0.3) Caso o interesse seja ver a contribuição de cada sexo para a distribuição total do peso, iremos trabalhar com o parâmetro position = \"stack\" ggplot(inv, aes(H_m, fill = Esp, color = Esp)) + geom_density(position = &quot;stack&quot;) A próxima variação é tratar os valores em porcentagem, do mesmo modo que fizemos com as barras. ggplot(inv, aes(H_m, fill = Esp, color = Esp)) + geom_density(position = &quot;fill&quot;) Boxplot O boxplot é um gráfico muito útil para demonstrar a distribuição dos dados. Seu objetivo é evidenciar os quartis e outliers. ggplot(inv, aes(Esp, H_m)) + geom_boxplot() Entretanto não vemos os pontos e muitas vezes o gráfico pode nos enganar pois não vemos quantos pontos cada fator tem de verdade. Como alternativa a isto, podemos plotar os pontos em conjunto. ggplot(inv, aes(Esp, H_m)) + geom_boxplot() + geom_point() Entretanto, mais uma vez o gráfico pode nos enganar pois a sobreposição dos pontos esconde a verdadeira quantidade. A alternativa para esta situação é utilizar a função jitter(), que adiciona uma variação aleatória aos pontos transformando-os em uma massa de pontos. Para não haver duplicidades nos outliers, podemos retirara-los do boxplot. ggplot(inv, aes(Esp, H_m)) + geom_boxplot(outlier.color = NA) + geom_jitter( width = 0.1, alpha = 0.5 ) Vilolin e dotplot Para os que não gostam ou não entendem o boxplot, uma alternativa de gráfico que expressa a mesma ideia é o violin plot. O gráfico consiste em uma curva de densidade simétrica para cada fator. ggplot(inv, aes(Esp, CAP_cm)) + geom_violin() Podemos ainda adicionar os pontos para ter uma noção de quantidade. ggplot(inv, aes(Esp, CAP_cm)) + geom_violin() + geom_jitter(alpha = 0.3, width = 0.1) Entretanto, o mais indicado é combinar o violin plot com o dot plot e assim evidenciar claramente a distribuição de frequência com uma curva de suavização. ggplot(inv, aes(Esp, CAP_cm)) + geom_violin() + geom_dotplot( binaxis=&quot;y&quot;, stackdir=&quot;center&quot;, dotsize = 1 ) Barras Para demonstrar como os diferentes tipos de agrupamento de barras funcionam, vamos criar um gráfico que possui contagem de diferentes categorias por fator. ggplot(resumo_clone, aes(Esp, CAP_cm)) + geom_col() Podemos adicionar a dimensão de color para verificar a diferença nos dado resumo_clone %&gt;% ggplot(aes(Esp, CAP_cm, fill = n_falha)) + geom_col() Texto Adição de texto e rótulos ao gráfico em forma de geometria. Caso queira inserir uma anotação, utiliza annotate(). Uma questão especial Há uma estético especial apenas para geom_text() ou geom_label() chamadas label, que define a coluna que deve ser utilizada como marcador de texto. ggplot(inv, aes(CAP_cm, H_m, label = Cod)) + geom_point() + geom_label() + annotate(&quot;text&quot;, 70, 10, label = &quot;Este é um comentário&quot;) Escalas Todos os tipos de escala (eixos x e y, cor, preenchimento e tamanho) tem funções específicas de controle e podem ser totalmente customizadas. Os eixos, por exemplo, são modificados pelas funções com o prefixo scale_[x|y]_**(). apropos(&quot;^scale_x_&quot;) scale_x_continuous, scale_x_discrete, scale_x_datetime e scale_x_date são os tipos básicos de eixos x e y que você pode modificar no ggplot2. scale_x_log10, scale_x_sqrt e scale_x_reverse são transformações básicas para uma escala contínua. Também veremos como criar nossa nossa sequência para composição de eixos. Existem alguns argumentos básicos par as funções relacionadas às escalas numéricas. name: Nome do eixo ou título da legenda. limits: Define o intervalo que os dados serão apresentados no gráfico. breaks: Marcadores dos eixos ou da legenda. labels: Rótulos dos marcadores. scale_x|y_continuous O ggplot2 determina uma escala e limite padrão para os gráficos de acordo com a escala de variação. Às vezes, queremos maior detalhe da escala e por isso temos que modificar os argumentos. ggplot(inv, aes(CAP_cm, H_m)) + geom_point() A alteração dos breacks é feita por um vetor que indica onde será adicionado o marcador do eixo. ggplot(inv, aes(CAP_cm, H_m)) + geom_point() + scale_x_continuous(breaks = seq(0, 90, 2)) Caso seja interessante altera o rotulo do marcador, temos que criar um novo vetor que contem os nomes. ggplot(inv, aes(CAP_cm, H_m)) + geom_point() + scale_x_continuous(breaks = seq(0, 90, 10), labels = paste(seq(0, 90, 10), &quot;cm&quot;)) Escalas de cor A paleta de cor é um ponto crítico em um gráfico. Muitas vezes utilizamos a dimensão de cor para comparar algo e por este motivo devemos escolher com cuidado as cores que iremos colocar. O ggplot2 disponibiliza algumas paletas e funções à nossa disposição. Vocês podem pesquisar cada uma delas mais tarde e ver qual o diferencial que cada uma trás. apropos(&quot;^scale_color_&quot;) A característica básica é que existem funções para variáveis discretas e funções para variais contínuas. Para variáveis discretas, por exemplo, a função padrão é a scale_[fill|color]_hue(). ggplot(inv, aes(CAP_cm, H_m, color = Esp)) + geom_point() + scale_fill_hue() O pacote RColorBrewer disponibiliza um conjunto de paletas que podem ser incorporadas no ggplot2. basta identificar qual você deseja. Há paletas sequenciais e paletas divergentes. Caso queria ver as paletas, explore pelo comando RColorBrewer::display.brewer.all(). No gráfico, basta indicar o nome da paleta no argumento palette. ggplot(inv, aes(CAP_cm, H_m, color = Esp)) + geom_point() + scale_color_brewer(palette = &quot;Set1&quot;) Caso você queria colocar suas próprias cores, terá de fazer isso manualmente. Eu recomendo o site http://colorbrewer2.org/. A partir do código hexadecimal, podemos colocar as cores que queremos com a função scale_[color|fill]_manual(). ggplot(inv, aes(CAP_cm, H_m, color = Esp)) + geom_point() + scale_color_manual(values = c(&quot;red&quot;, &quot;blue&quot;, &quot;darkgreen&quot;, &quot;gold&quot;, &quot;cyan&quot;, &quot;#fc9272&quot;, &quot;#4a1486&quot;)) Se for preciso economizar na impressão e colocar o gráfico em escala de cinza, sem problema, temos uma função pronta para isto. ggplot(inv, aes(CAP_cm, H_m, color = Esp)) + geom_point() + scale_color_grey() Facets Talvez o recuso mais interessante do R e ggplot2 no contexto de gráficos exploratórios seja a possibilidade (e facilidade) de criar gráficos em painéis. Esse pode ser feito em outros softwares, mas o ggplot2 oferece uma gama de funcionalidades relacionadas a este tema. ggplot(inv, aes(CAP_cm, H_m, color = Esp)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~Esp) + scale_color_brewer(palette = &quot;Dark2&quot;) "],
["regressao-e-anova.html", "Regressão e ANOVA Regressão Linear ANOVA e Tukey", " Regressão e ANOVA Regressão Linear Uma regressão linear é um modelo estatístico que analisa a relação entre uma variável de resposta (muitas vezes chamada de y) e uma ou mais variáveis e suas interações (frequentemente chamadas x ou variáveis explicativas). Você faz esse tipo de relacionamento em sua cabeça o tempo todo, por exemplo, quando você calcula a idade de uma criança com base em sua altura, você está assumindo que quanto mais velha ela é, mais alta ela será. A regressão linear é um dos modelos estatísticos mais básicos, seus resultados podem ser interpretados por quase todos, e existe desde o século XIX. É precisamente isso que torna a regressão linear tão popular library(tidyverse) library(modelr) library(broom) library(car) library(agricolae) vendas &lt;- read_csv2(&quot;input/propagandas.csv&quot;) vendas Regressão linear simples faz jus ao seu nome: é uma abordagem muito simples para prever uma resposta quantitativa \\(Y\\) com base em uma única variável preditor X. Ele assume que há aproximadamente uma relação linear entre \\(X\\) e \\(Y\\). Usando nossos dados de publicidade, suponha que desejamos modelar a relação linear entre o orçamento de TV e as vendas. Podemos escrever isso como: \\[ Y = \\beta_0 + \\beta_1X + \\epsilon \\tag{1}\\] Onde: - \\(Y\\) representa vendas - \\(X\\) representa orçamento de publicidade na TV - \\(\\beta_0\\) intercepto do eixo Y - \\(\\beta_1\\) coeficiente (termo de inclinação) representando o relacionamento linear - \\(\\epsilon\\) erro aleatório com média zero Para construir este modelo em R usamos a notação de fórmula de \\(Y \\sim X\\). modelo1 &lt;- lm(vendas ~ tv, data = vendas) A função lm, que significa “modelo linear”, está produzindo o relacionamento linear de melhor ajuste, minimizando o critério de mínimos quadrados. Esse ajuste pode ser visualizado na ilustração a seguir, onde a linha do “melhor ajuste” é encontrada, minimizando a soma de erros quadrados (os erros são representados pelos segmentos de linhas pretas verticais). Para avaliação inicial do nosso modelo, podemos usar o summary. Isso nos fornece uma série de informações sobre o nosso modelo. Alternativamente, você também pode usar glance(model1) para ter o resultado em uma forma tabelada e mais “arrumada”. summary(modelo1) A fórmula da equação apresenta o \\(\\beta_0\\) (intercepto) e o \\(\\beta_1\\) (coeficiente de inclinação). A forma de utilização do modelo é \\[ Y = 7.03 + 0.04X + \\epsilon \\tag{2}\\] Alternativamente podemos acessar os coeficientes de uma forma mais organizada utilizando a função tidy() tidy(modelo1) Em outras palavras, nossa estimativa de interceptação é de 7,03, portanto, quando o orçamento de publicidade na TV for zero, podemos esperar que as vendas sejam de 7.03. E para cada aumento de R$ 1 no orçamento de publicidade de TV, esperamos que o aumento médio nas vendas 0.04 unidades. Também é importante entender até que ponto o modelo se ajusta aos dados. Isto é tipicamente referido como o goodness-of-fit. O RSE (erro padrão da estimativa) é uma estimativa do desvio padrão de \\(\\epsilon\\). Grosso modo, é a quantidade média que a resposta se desviará da verdadeira linha de regressão. Um valor de RSE de 3,2 significa que as vendas reais em cada mercado se desviarão da linha de regressão real em aproximadamente 3,2 unidades, em média. O RSE fornece uma medida absoluta sobre ajuste do modelo nos dados. Mas como a escala dele é na mesma unidades de \\(Y\\), nem sempre é fácil de interpretar o resultado. O \\(R^2\\) é uma estatística fornece uma medida alternativa de avaliação. Ele representa a proporção de variância explicada e, portanto, sempre assume um valor entre 0 e 1 e é independente da escala de \\(Y\\). Não só é importante entender as medidas quantitativas com relação ao nosso coeficiente e precisão do modelo, mas também devemos entender as abordagens visuais para avaliar nosso modelo. ggplot(vendas, aes(tv, vendas)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + geom_smooth(se = FALSE, color = &quot;red&quot;) Primeiro é um gráfico de resíduos versus valores ajustados. Isso sinalizará duas preocupações importantes: Não-linearidade: se existir um padrão discernível (linha azul), isso sugere não-linearidade ou que outros atributos não foram adequadamente capturados. Nosso enredo indica que a suposição de linearidade é justa. Heteroscedasticidade: uma suposição importante da regressão linear é que os termos de erro têm uma variância constante, Se houver uma forma de funil com nossos resíduos, como em nossa trama, violamos essa suposição. Às vezes isso pode ser resolvido com uma transformação de log ou raiz quadrada de \\(Y\\) em nosso modelo. modelo1_resultado &lt;- augment(modelo1, vendas) ggplot(modelo1_resultado, aes(.fitted, .resid)) + geom_ref_line(h = 0) + geom_point() + geom_smooth(se = FALSE) + ggtitle(&quot;Residuals vs Fitted&quot;) Se quisermos executar um modelo que usa TV, rádio e jornal para prever vendas, então construímos esse modelo em R usando uma abordagem semelhante introduzida no tutorial Regressão Linear Simples. modelo2 &lt;- lm(vendas ~ tv + radio + jornal, data = vendas) Podemos também avaliar este modelo como antes: summary(modelo2) A interpretação dos nossos coeficientes é a mesma de um modelo de regressão linear simples. Primeiro, vemos que nossos coeficientes para orçamento de publicidade de TV e rádio são estatisticamente significativos (p-valor &lt;0,05), enquanto o coeficiente de jornal não é. Assim, as alterações no orçamento do jornal não parecem ter um relacionamento com as mudanças nas vendas. No entanto, para a TV, nosso coeficiente sugere que, para cada aumento de R$ 1 no orçamento de publicidade de TV, mantendo todos os outros preditores constantes, podemos esperar um aumento de 0,045 unidades de vendas, em média (isso é semelhante ao que encontramos na regressão linear simples). O coeficiente de rádio sugere que para cada aumento de R$ 1 no orçamento de publicidade de rádio, mantendo todos os outros preditores constantes, podemos esperar um aumento de 0,188 unidades de vendas, em média. tidy(modelo2) A avaliação da precisão do modelo é muito semelhante à avaliação de modelos de regressão linear simples. Se compararmos os resultados do nosso modelo de regressão linear simples (modelo1) com o modelo de regressão múltipla (modelo2), podemos fazer algumas comparações importantes e concluir que as estatísticas indicam uma melhora significativa no ajuste do modelo2 glance(modelo1); glance(modelo2) ANOVA e Tukey Iremos realizar uma análise paramétrica básica envolvendo análise de variância e teste de Tukey num conjunto de dados bastante simples. Além dos testes estatísticos, iremos fazer um gráfico para expressar o resultado de forma agradável. O banco de dados é proveniente de um Teste de Progênie, onde se testa diferentes materiais genéticos com o intuito selecionar indivíduos superiores. dados &lt;- read_csv2(&quot;input/progenies.csv&quot;) dados Uma ideia básica é verificar a distribuição dos dados. Utilizaremos o boxplot para isso. ggplot(dados, aes(progenie, volume)) + geom_boxplot() + theme_bw() Primeiro, vamos utilizar o teste de Levene para verificar se há homogeneidade de variância, ou homocedasticidade. leveneTest(volume ~ factor(progenie), data=dados) Como o p-valor é maior que 5% não temos evidência significativa para rejeitar a hipótese nula de homogeneidade, ou seja, nossos dados tem homogeneidade de variância. O segundo pressuposto é a normalidade dos resíduos. Utilizaremos o teste de Shapiro-Wilk cuja hipótese nula é a de que os dados seguem uma distribuição normal. anova &lt;- aov(volume ~ progenie, data=dados) shapiro.test(resid(anova)) Como o p-valor é superior ao limite de 5%, podemos aceitar a hipótese nula e considerar nossos dados normais. Uma vez que os pressupostos foram atendidos, seguiremos para a ANOVA. Note que, caso os testes de Levene e Shapiro-Wilk resultassem em um p-valor significante, ou seja, menor que 5%, teríamos que utilizar outro método estatístico para analisar nossos dados. Nesse caso, uma alternativa é utilizar testes não-paramétricos, uma vez que eles não exigem os pressupostos que acabamos de testar. summary(anova) Nossa ANOVA resultou em um p-valor menor que 5%, portanto, temos evidências de que ao menos um tratamento se diferencia dos demais. Isso já é uma resposta, mas pouco acrescenta à nossa pesquisa pois queremos saber quem é este tratamento discrepante. Ou melhor, queremos poder comparar os tratamentos entre si e verificar quais são estatisticamente iguais ou diferentes. Para esta abordagem existem alguns testes de médias e cada um tem uma particularidade, mas de longe o mais utilizado é o de Tukey. A interpretação do teste de Tukey é simples. Após determinarmos a diferença mínima significativa (ou Honest Significant Difference - HSD), podemos julgar se as médias são iguais ou não. Em termos práticos, esse valor nos dá uma margem de igualdade, pois se a diferença entre dois tratamentos for maior do que isso, os médias são diferentes. tukey &lt;- HSD.test(anova, &quot;progenie&quot;) tukey Para deixar mais visual ainda, podemos construir um gráfico de barras com a média de cada tratamento e adicionar a sua letra correspondente ao teste de Tukey. tukey$groups %&gt;% rownames_to_column(var = &quot;trt&quot;) %&gt;% ggplot(aes(reorder(trt, -volume), volume)) + geom_bar(stat = &quot;identity&quot;) + geom_text(aes(label = groups), vjust = 1.8, size = 9, color = &quot;white&quot;) + labs(x = &quot;Progênies&quot;, y = &quot;Médias&quot;) + theme_bw() "],
["estrutura-de-objetos-e-elementos.html", "Estrutura de objetos e elementos Vetores Fatores Matrizes e arrays Lists Data frame Missing values Exercícios", " Estrutura de objetos e elementos Para fazer o melhor uso da linguagem R, você precisará de uma forte compreensão dos tipos de objetos e estruturas de dados. É muito importante compreender isto, porque estes são os objetos que você vai manipular no dia-a-dia no R. Lidar com conversões de objetos é uma das fontes mais comuns de frustração para quem está começando. To understand computations in R, two slogans are helpful: - Everything that exists is an object. - Everything that happens is a function call. John Chambers Primeiro vamos falar dos elementos, ou seja, a matéria prima dentro de um objeto. No R, os tipos de elementos mais utilizados são: character numeric integer logical Veja abaixo o exemplo de cada classe. Note que utilizamos o L para indicar o número inteiro. Exemplo Tipo “a”, “swc” character 2, 15.5 numeric 2L integer TRUE, FALSE logical Vamos fazer alguns testes para exemplificar os tipos na prática. library(tidyverse) x &lt;- &quot;dataset&quot; typeof(x) y &lt;- 1:10 typeof(y) length(y) z1 &lt;- c(1L, 2L, 3L) z2 &lt;- c(1, 2, 3) typeof(z1) typeof(z2) Como em qualquer outra linguagem de programação, o R tem em sua concepção tipos e estruturas de dados que determinam como será o comportamento durante os processos. Os tipos de dados são estes: Homogêneo Heterogêneo 1d Atomic vector List 2d Matrix Data frame nd Array É importante entender a diferença entre estes tipo de objetos pois cada um dele tem um comportamento diferente e exigem tipos específicos de elementos. Vetores Um vetor é a estrutura de dados mais comum e básica do R. Tecnicamente, os vetores podem ser de dois tipos: atomic vectors e lists. No dia a dia, utilizamos o termo vector para se referir ao objeto comumente se refere ao tipo atômico, não listas. Um vector pode ser do tipo character,logical, integer ounumeric, o que nos remete ao tipo de elemento que ele armazena. Você pode criar um vetor vazio com vector() (por padrão, o modo é logical. Você pode ser mais direto e especificar outro tipo de elemento). Outra forma é usar construtores diretos como character(), numeric(), etc. x &lt;- vector() vector(&quot;character&quot;, length = 10) logical(5) x &lt;- c(1, 2, 3) length(x) x é um vetor numérico. Para criar inteiros explicitamente, adicione um L no final. x1 &lt;- c(1L, 2L, 3L) Você também pode ter um vetor de caracteres. z &lt;- c(&quot;Alex&quot;, &quot;Danilo&quot;, &quot;Maria&quot;, &quot;Jéssica&quot;) Para saber mais sobre o seu vetor. typeof(z) length(z) class(z) str(z) Adicionando elementos com o contatenador básico c(). z &lt;- c(z, &quot;João&quot;) Você também pode criar vetores como uma sequência de números. series &lt;- 1:10 seq(10) seq(1, 10, by = 0.1) O que acontece quando você mistura tipos? Primeiro tente adivinhar o que o comandos abaixo vão fazer e depois execute no console. xx &lt;- c(1.7, &quot;a&quot;, &quot;B&quot;) xx &lt;- c(TRUE, FALSE, 2) xx &lt;- c(&quot;a&quot;, TRUE) Isso é chamado de coerção implícita. Você também pode forçar vetores explicitamente usando o as.&lt;Class_name&gt;. Exemplo as.numeric() as.character() x &lt;- 0:6 as.logical(x) as.character(x) Entretanto, coerções absurdas não funcionam. x &lt;- c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) as.numeric(x) as.logical(x) Fatores Fatores são vetores especiais que representam dados categóricos. Os fatores podem ser ordenados ou desordenados e são importantes para funções de modelagem como lm() e glm() e também na criação de gráficos. Os fatores são números inteiros que têm rótulos sobre eles. Enquanto os fatores parecem (e muitas vezes se comportam) como vetores de caracteres, eles são inteiros sob o capô, e você precisa ter cuidado ao tratá-los como caracteres. Fatores podem ser criados com factor(). A entrada é geralmente um vetor de caracteres. x &lt;- factor(c(&quot;sim&quot;, &quot;nao&quot;, &quot;sim&quot;, &quot;nao&quot;, &quot;sim&quot;)) Se você precisa converter um fator em um vetor de caracteres, simplesmente use: as.character(x) Nas funções de modelagem, é importante saber qual é o nível de linha de base. Este é o primeiro fator, mas por padrão o pedido é determinado por ordem alfabética das palavras inseridas. Você pode alterar isso especificando os níveis (outra opção é usar a função fct_relevel). x &lt;- factor(c(&quot;sim&quot;, &quot;nao&quot;, &quot;sim&quot;), levels = c(&quot;sim&quot;, &quot;nao&quot;)) x fct_relevel(x, &quot;nao&quot;, &quot;sim&quot;) Matrizes e arrays Se acrescentarmos mais dimensões aos vetores teremos matrizes (2d) e arrays (ou arranjos) para várias dimensões. matrix(data = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, 1, 2, 3), ncol = 3, nrow = 2) x &lt;- matrix(data = 1:6, ncol = 3, nrow = 2) x typeof(x) class(x) x &lt;- array(data = 1:18, dim = c(2, 3, 3)) x typeof(x) class(x) x &lt;- list(1:3, &quot;a&quot;, TRUE, 1.0, matrix(1:6, ncol = 3, nrow = 2)) x typeof(x) class(x) Lists As listas são vetores com flexibilidade quanto ao tipo do elemento. Para criá-la basta usar list() ao invés de c(). x &lt;- list(1:3, &quot;a&quot;, c(TRUE, FALSE, TRUE), c(2.3, 5.9)) x str(x) Data frame Objetos do tipo data.frame são os mais comuns quando estamos trabalhando no R. Você pode entender um data frame como um conjunto de vetores, ou como uma matriz com maior flexibilidade. Quando você combina colunas, o números de linhas precisam corresponder. Se você estiver adicionando um vetor, ele será repetido pelo princípio do recycling df &lt;- data.frame(id = letters[1:10], x = 1:10, y = rnorm(10), z = 4) tbl &lt;- tibble(id = letters[1:10], x = 1:10, y = rnorm(10), z = 4) Algumas funções úteis que lidam com data frames head() - veja as primeiras 6 linhas tail() - veja as últimas 6 linhas dim() - ver dimensões nrow() - número de linhas ncol() - número de colunas str() - estrutura de cada coluna bind_rows - empilhas as linhas dos data.frames com colunas equivalentes bind_cols - junta colunas de data.frames com o mesmo número de linhas Missing values Denotado por NA e / ouNaN para operações matemáticas indefinidas. is.na(100) is.nan(0/0) x &lt;- c(1, 2, NA, 4, 5) mean(x) mean(x, na.rm = TRUE) na.omit(x) Exercícios Crie um vetor de caracteres que 20 elementos quaisquer. #&gt; [1] &quot;g&quot; &quot;e&quot; &quot;t&quot; &quot;b&quot; &quot;o&quot; &quot;k&quot; &quot;n&quot; &quot;p&quot; &quot;a&quot; &quot;l&quot; &quot;m&quot; &quot;c&quot; &quot;d&quot; &quot;i&quot; &quot;r&quot; &quot;q&quot; &quot;f&quot; #&gt; [18] &quot;s&quot; &quot;j&quot; &quot;h&quot; Crie uma sequência de 50 a 150, somente com numeros pares. #&gt; [1] 50 52 54 56 58 60 62 64 66 68 70 72 74 76 78 80 82 #&gt; [18] 84 86 88 90 92 94 96 98 100 102 104 106 108 110 112 114 116 #&gt; [35] 118 120 122 124 126 128 130 132 134 136 138 140 142 144 146 148 150 Crie um vetor lógico com 4 elementos, armazene em um objeto e em seguida trasforme em um vetor numérico. #&gt; [1] TRUE FALSE TRUE TRUE #&gt; [1] 1 0 1 1 Crie uma vector de caracteres quaisquer que possua 2 fatores. #&gt; [1] a b a b a b a b a b a b a b a b a b a b a b a b a b a b a b #&gt; Levels: a b Crie um data frame com 3 colunas e 10 linhas utilizando números aleatórios para o compor. #&gt; x y z #&gt; 1 -0.236918034 -0.48832377 1.5791733 #&gt; 2 0.209041392 2.46034851 -1.2978575 #&gt; 3 1.594494569 -2.93769813 0.8046953 #&gt; 4 -0.388472845 -2.19728450 -0.8040328 #&gt; 5 0.608257271 1.19193302 0.4315485 #&gt; 6 0.752073053 -0.82293139 0.7896385 #&gt; 7 -0.741333344 -1.36321722 -0.9090382 #&gt; 8 0.207068624 -0.77813055 -0.2827280 #&gt; 9 -0.334033498 0.08450971 -0.7932897 #&gt; 10 0.003045311 0.77610512 1.0454384 Crie um vetor com 10 numeros aleatorios e armazene-o em um objeto de nome ‘x’. Em seguida mostre seu conteúdo. #&gt; [1] 0.3065743 0.4444781 0.1909876 0.9505543 -2.0747753 -0.9263543 #&gt; [7] 1.3569865 1.3645342 0.6529419 1.0725909 "],
["indexacao.html", "Indexação Vetores Listas Matrizes Data frames Exercícios", " Indexação O R tem muitos operadores de indexação e dominá-los permitirá que você execute facilmente uma operação complexa em qualquer tipo de conjunto de dados. Permite manipular dados de forma muito sucinta. Vetores x &lt;- c(5.4, 6.2, 7.1, 4.8) Nós podemos indexar valores de um objeto de 4 maneiras. Usando inteiros positivos. x[1] x[c(3,1)] x[c(1, 1)] x[c(2.1, 2.9)] Usando números inteiros negativos. x[-1] x[-c(1, 5)] Usando operadores lógicos. x[c(TRUE, TRUE, FALSE, FALSE)] x[x &gt; 3] x[which(x &gt;3)] Referenciando objetos por seus nomes. y &lt;- setNames(x, letters[1:4]) y[c(&quot;d&quot;, &quot;c&quot;, &quot;a&quot;)] y[c(&quot;a&quot;, &quot;a&quot;, &quot;a&quot;)] z &lt;- c(abc = 1, def = 2) z[c(&quot;a&quot;, &quot;d&quot;)] Listas Indexar uma lista funciona exatamente da mesma maneira como subconjunto de um vetor atômico. Indexar uma lista com [ sempre retornará uma lista: [[ e $, conforme descrito abaixo, permitem que você retire os componentes da lista. x &lt;- as.list(1:10) x[1:5] Para extrair elementos individuais dentro de uma lista, use o operador [[. x[[5]] class(x[[5]]) another_variable &lt;- x[[5]] Ou usando seus nomes. names(x) &lt;- letters[1:5] x$a x[[&quot;a&quot;]] Matrizes Uma matriz é um subconjunto com dois argumentos dentro de colchetes simples, [], e separados por uma vírgula. O primeiro argumento especifica as linhas e o segundo as colunas. a &lt;- matrix(1:9, nrow = 3) colnames(a) &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;) a[1:2, ] a[c(T, F, T), c(&quot;B&quot;, &quot;A&quot;)] a[0, -2] Data frames df &lt;- data.frame(x = 1:3, y = 3:1, z = letters[1:3]) df[df$x == 2, ] df[c(1, 3), ] Há duas maneiras de selecionar colunas de um data frame, como Como uma lista ou como uma matriz. df[c(&quot;x&quot;, &quot;z&quot;)] df[c(1, 3)] df[, c(&quot;x&quot;, &quot;z&quot;)] Há uma diferença importante se você selecionar uma coluna simples: o subconjunto de matriz simplifica por padrão, o subconjunto de lista não. df[, &quot;x&quot;] df[&quot;x&quot;] Exercícios Crie um vetor chamado ‘y’ com os 30 numeros aleatórios. Mostre todos os numeros do vetor e em segue mostre apenas o quinto e o ultimo elemento. #&gt; [1] -0.496735894 -0.307230029 1.259041790 1.564497209 -1.537230527 #&gt; [6] -1.333390731 -0.176819026 -0.234252829 0.280553296 -0.383512630 #&gt; [11] -0.236918034 0.209041392 1.594494569 -0.388472845 0.608257271 #&gt; [16] 0.752073053 -0.741333344 0.207068624 -0.334033498 0.003045311 #&gt; [21] -0.488323772 2.460348506 -2.937698132 -2.197284502 1.191933021 #&gt; [26] -0.822931391 -1.363217219 -0.778130555 0.084509709 0.776105123 #&gt; [1] -1.5372305 0.7761051 Armazene este data frame data.frame(a = letters[1:10], b = 10:1) em um objeto de nome ‘x’. Em seguida mostre seu conteúdo. #&gt; a b #&gt; 1 a 10 #&gt; 2 b 9 #&gt; 3 c 8 #&gt; 4 d 7 #&gt; 5 e 6 #&gt; 6 f 5 #&gt; 7 g 4 #&gt; 8 h 3 #&gt; 9 i 2 #&gt; 10 j 1 Extraia do data frame ‘x’ apenas a columa a, de forma que o resultado seja um vetor. #&gt; [1] a b c d e f g h i j #&gt; Levels: a b c d e f g h i j Extraia do data frame ‘x’ todas as linhas que tenham na coluna b um número menor que 7. #&gt; a b #&gt; 5 e 6 #&gt; 6 f 5 #&gt; 7 g 4 #&gt; 8 h 3 #&gt; 9 i 2 #&gt; 10 j 1 "],
["strings-fatores-e-datas.html", "Strings, fatores e datas Strings Fatores Datas Exercícios", " Strings, fatores e datas Neste bloco vamos trabalhar com tipos de elementos que em bancos de dados. Aprender a manipular strings (palavras), factors e dates vai nos dar um poder de análise diversificado e útil. Strings A verdade é que nem sempre nosso banco de dados está bem formatado. Por diversos motivos, os dados chegam com uma formatação muito distante do ideal e não é raro termos de limpar os dados antes de iniciar uma análise. Variável que trazem caracteres são as que mais precisam de atenção e limpeza. O R tem suporte à regular expression ou regex, uma forma muito utilizada em linguagens de programação para identificar padrões de caracteres através de uma sintaxe própria. Vamos ver alguns exemplos de como utilizá-la. As funções que iremos trabalhar estão disponíveis no pacote stringr, que faz parte do tidyverse. Como exemplo vamos utilizar um objeto interno (vetor) com nomes de frutas. fruit O primeiro passo é detectar padrões dentro do vetor de caracteres. Podemos usar esse vetor lógico para filtrar os elementos que queremos. str_detect(fruit, pattern = &quot;fruit&quot;) fruit[str_detect(fruit, pattern = &quot;fruit&quot;)] tem_fruit &lt;- str_subset(fruit, pattern = &quot;fruit&quot;) Podemos retirar uma parte fixa das palavras através da posição de cada caractere. str_sub(fruit, 1, 5) Também podemos concatenar e colapsar palavras utilizando diferentes padrões. tem_berry &lt;- str_subset(fruit, &quot;berry&quot;) %&gt;% sample(8) str_c(tem_fruit, tem_berry, sep = &quot; &amp; &quot;) str_c(tem_fruit, tem_berry, sep = &quot; + &quot;, collapse = &quot;; &quot;) Em muitos casos precisamos substituir determinada cadeia de caractere. Vamos ver alguns exemplos. str_replace(tem_berry, pattern = &quot;berry&quot;, replacement = &quot;beRRy&quot;) melons &lt;- str_subset(fruit, pattern = &quot;melon&quot;) melons[2] &lt;- NA melons str_replace_na(melons, &quot;Não sei&quot;) Agora vamos mudar para outra base de dados. O pacote gapminder disponibiliza dados de expectativa de vida, população e renda per capta dos países ao longo dos anos. Utilizaremos para testar os marcadores de Regex. Em Regex, utilizamos os marcadores ^ e $ para indicar os primeiros ou últimos caractere de uma string, respectivamente. Portanto, se quisermos filtrar os países que terminam com a sequencia de caracteres, podemos fazer da seguinte forma. library(gapminder) paises &lt;- levels(gapminder$country) paises str_subset(paises, pattern = &quot;land$&quot;) str_subset(paises, pattern = &quot;^Ma&quot;) Aumentando um pouco a complexidade da busca, vamos usar o marcador [ para indicar um grupo de possibilidade. Quais países terminam com as letras: nia, lia, sia? str_subset(paises, pattern = &quot;[nls]ia$&quot;) O R possui alguns grupos pre formatados para facilitar a correspondência, como: [:blank:], [:upper:], [:lower:], [:alpha:], [:digit:], [:alnum:], [:punct:] str_subset(paises, &quot;[:punct:]&quot;) str_subset(paises, &quot;[:blank:]&quot;) Agora vamos ver como extrais padrões entre determinados identificadores dentro de uma cadeia de caractere. Em Regex o . significa ‘qualquer coisa’, o * significa ‘um ou mais em diante’. Utilizaremos esses marcadores para extrair países que tenham uma cadeia de caractere que começa com a letra m, em seguida possa ter qualquer letra ou ponto, e termine com a letra a. str_subset(paises, &quot;a.*e&quot;) Dando um exemplo mais avançado, vamos filtrar os países que possuem , no nome e em seguida retirar todos caracteres após a vírgula. str_subset(paises, &quot;,&quot;) str_subset(paises, &quot;,&quot;) %&gt;% str_remove(&quot;,.*&quot;) Fatores Já falamos um pouco sobre os fatores anteriormente e agora vamos tentar usar eles como recurso para criação de gráficos. class(gapminder$continent) str(gapminder$continent) nlevels(gapminder$continent) levels(gapminder$continent) A grande dica é: só convertam caracteres em fatores quando necessário e fiquem sempre de olho se uma variável é ou não um fator. De maneira geral, variáveis como fatores podem dar dor de cabeça em alguns passos durante a análise e recomendável que se utilize sempre caracteres em variáveis qualitativas. Aqui vai um primeiro problema. Mesmo se você filtrar um elemento, os níveis do fator ainda fica lá no objeto. nlevels(gapminder$country) aux_sulamerica &lt;- c(&quot;Argentina&quot;, &quot;Bolivia&quot;, &quot;Brazil&quot;, &quot;Chile&quot;, &quot;Colombia&quot;, &quot;Ecuador&quot;, &quot;Paraguay&quot;, &quot;Peru&quot;, &quot;Uruguay&quot;, &quot;Venezuela&quot;) sulamerica &lt;- gapminder %&gt;% filter(country %in% aux_sulamerica) nlevels(sulamerica$country) No momento de plotar um gráfico, o ggplot2 converte internamente todas as variáveis do tipo caractere como fator. Se já for um fator, ele deixa como está. Ele faz isso por conta da ordem que os elementos aparecem no gráfico. Por exemplo um eixo de nomes ou os níveis da legenda. No exemplo abaixo o ggplot2 seque a ordem dos níveis do fator da variável country, que por sua vez é alfabética. Mas se alterarmos a ordem dos níveis do fator utilizando a função fct_reorder, podemos ter um eixo ordenado em função da lifeExp. gap_asia_2007 &lt;- gapminder %&gt;% filter(year == 2007, continent == &quot;Asia&quot;) ggplot(gap_asia_2007, aes(x = lifeExp, y = country)) + geom_point() ggplot(gap_asia_2007, aes(x = lifeExp, y = fct_reorder(country, lifeExp))) + geom_point() gap_1992 &lt;- gapminder %&gt;% filter(year == 1992 ) %&gt;% group_by(continent) %&gt;% summarise(lifeExp = mean(lifeExp)) gap_1992 %&gt;% ggplot(aes(continent, lifeExp, fill = continent)) + geom_col() gap_1992 %&gt;% mutate(continent = fct_relevel(continent, &quot;Oceania&quot;, &quot;Asia&quot;)) %&gt;% ggplot(aes(continent, lifeExp, fill = continent)) + geom_col() gap_1992 %&gt;% mutate(continent = fct_recode(continent, &quot;Oceania 2&quot; = &quot;Oceania&quot;)) %&gt;% ggplot(aes(continent, lifeExp, fill = continent)) + geom_col() gap_1992 %&gt;% mutate(continent = fct_reorder(continent, -lifeExp)) %&gt;% ggplot(aes(continent, lifeExp, fill = continent)) + geom_col() Datas Neste bloco vamos trabalhar com a classe de objeto do tipo data. Dentro do tidyverse, o pacote que reúne as funções relacionadas a datas é o lubridate. É importante mencionar que no é temos os tipos date e date-time ou POSIXct. A diferença entre esses dois tipos é a resolução, sendo que a classe date-time armazena além da data, a informação de hora-minuto-segundo. Começando pelo começo, vamos criar objetos do tipo date e date-time. library(tidyverse) library(lubridate) hoje &lt;- today() hoje class(hoje) str(hoje) agora &lt;- now() agora class(agora) str(agora) Note que o R utiliza o padrão ISO para mostrar as datas (yyyy-mm-dd). Quando a informação está armazenada nesse padrão, é comum os importadores reconhecerem a variável como data e fazer a conversão adequada. Mas se isso não acontecer, teremos que converter na mão utilizando as funções auxiliares do lubridate. ymd(&quot;20190408&quot;) mdy(&quot;01-15-2013&quot;) dmy(&quot;07/09/2010&quot;) Existem várias funções interessantes no pacote e elas são extremamente úteis no dia a dia. Podemos arredondar datas para várias unidades de referencia e computar o dia do ano, mês ou semana. Para fazer operações aritméticas com datas temos que entender o conceito importante de period e duration, onde o primeiro considera sempre um ano com 365 dias e o segundo é sensível a anos bissexto. inicio &lt;- ymd(&quot;20000223&quot;) fim &lt;- ymd(&quot;20161207&quot;) floor_date(inicio, &quot;month&quot;) ceiling_date(inicio, &quot;week&quot;) yday(fim) mday(fim) inicio + years(3) inicio + dyears(3) inicio - months(36) Para calcular o intervalo entre duas datas e converter isso em diversas unidades, também é fácil. fim - inicio time_length(fim - inicio, &quot;year&quot;) time_length(fim - inicio, &quot;month&quot;) time_length(fim - inicio, &quot;week&quot;) Exercícios Importe o arquivo nobel_winners.csv e use a função glimpse() para ver a estrutura da base. #&gt; Observations: 969 #&gt; Variables: 18 #&gt; $ prize_year &lt;dbl&gt; 1901, 1901, 1901, 1901, 1901, 1901, 1902,... #&gt; $ category &lt;chr&gt; &quot;Chemistry&quot;, &quot;Literature&quot;, &quot;Medicine&quot;, &quot;P... #&gt; $ prize &lt;chr&gt; &quot;The Nobel Prize in Chemistry 1901&quot;, &quot;The... #&gt; $ motivation &lt;chr&gt; &quot;\\&quot;in recognition of the extraordinary se... #&gt; $ prize_share &lt;chr&gt; &quot;1/1&quot;, &quot;1/1&quot;, &quot;1/1&quot;, &quot;1/2&quot;, &quot;1/2&quot;, &quot;1/1&quot;,... #&gt; $ laureate_id &lt;dbl&gt; 160, 569, 293, 462, 463, 1, 161, 571, 294... #&gt; $ laureate_type &lt;chr&gt; &quot;Individual&quot;, &quot;Individual&quot;, &quot;Individual&quot;,... #&gt; $ full_name &lt;chr&gt; &quot;Jacobus Henricus van &#39;t Hoff&quot;, &quot;Sully Pr... #&gt; $ birth_date &lt;date&gt; 1852-08-30, 1839-03-16, 1854-03-15, 1828... #&gt; $ birth_city &lt;chr&gt; &quot;Rotterdam&quot;, &quot;Paris&quot;, &quot;Hansdorf (Lawice)&quot;... #&gt; $ birth_country &lt;chr&gt; &quot;Netherlands&quot;, &quot;France&quot;, &quot;Prussia (Poland... #&gt; $ gender &lt;chr&gt; &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;, &quot;... #&gt; $ organization_name &lt;chr&gt; &quot;Berlin University&quot;, NA, &quot;Marburg Univers... #&gt; $ organization_city &lt;chr&gt; &quot;Berlin&quot;, NA, &quot;Marburg&quot;, NA, NA, &quot;Munich&quot;... #&gt; $ organization_country &lt;chr&gt; &quot;Germany&quot;, NA, &quot;Germany&quot;, NA, NA, &quot;German... #&gt; $ death_date &lt;date&gt; 1911-03-01, 1907-09-07, 1917-03-31, 1910... #&gt; $ death_city &lt;chr&gt; &quot;Berlin&quot;, &quot;Châtenay&quot;, &quot;Marburg&quot;, &quot;Heiden&quot;... #&gt; $ death_country &lt;chr&gt; &quot;Germany&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Switzerl... Crie um novo data frame chamado nobel_age. Neste novo data frame filtre apenas os prêmios individuais em laureate_type e em seguida crie uma coluna chamada prize_date considerando o dia 1 de dezembro do ano em que o premio foi entregue. Em seguida calcule a idade em que o ganhador recebeu o prêmio e armazene em uma variável chamada age neste mesmo data frame. Dicas: str_glue, ymd, time_length. #&gt; # A tibble: 939 x 20 #&gt; prize_year category prize motivation prize_share laureate_id #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 1901 Chemist~ The ~ &quot;\\&quot;in rec~ 1/1 160 #&gt; 2 1901 Literat~ The ~ &quot;\\&quot;in spe~ 1/1 569 #&gt; 3 1901 Medicine The ~ &quot;\\&quot;for hi~ 1/1 293 #&gt; 4 1901 Peace The ~ &lt;NA&gt; 1/2 462 #&gt; 5 1901 Peace The ~ &lt;NA&gt; 1/2 463 #&gt; 6 1901 Physics The ~ &quot;\\&quot;in rec~ 1/1 1 #&gt; 7 1902 Chemist~ The ~ &quot;\\&quot;in rec~ 1/1 161 #&gt; 8 1902 Literat~ The ~ &quot;\\&quot;the gr~ 1/1 571 #&gt; 9 1902 Medicine The ~ &quot;\\&quot;for hi~ 1/1 294 #&gt; 10 1902 Peace The ~ &lt;NA&gt; 1/2 464 #&gt; # ... with 929 more rows, and 14 more variables: laureate_type &lt;chr&gt;, #&gt; # full_name &lt;chr&gt;, birth_date &lt;date&gt;, birth_city &lt;chr&gt;, #&gt; # birth_country &lt;chr&gt;, gender &lt;chr&gt;, organization_name &lt;chr&gt;, #&gt; # organization_city &lt;chr&gt;, organization_country &lt;chr&gt;, #&gt; # death_date &lt;date&gt;, death_city &lt;chr&gt;, death_country &lt;chr&gt;, #&gt; # prize_date &lt;date&gt;, age &lt;dbl&gt; Filtre quem ganhou o prêmio com menos de 30 anos e mostre apenas as seguintes variáveis: prize_year, category, full_name, birth_country, prize_date e age. #&gt; # A tibble: 2 x 6 #&gt; prize_year category full_name birth_country prize_date age #&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; #&gt; 1 1915 Physics William Lawrence Bragg Australia 1915-12-01 25.7 #&gt; 2 2014 Peace Malala Yousafzai Pakistan 2014-12-01 17.4 Faça um histograma com as idades dos ganhadores. Faça um gráfico de dispersão com o ano do prêmio e a idade do ganhador e coloque uma linha de tendência. Dica: geom_smooth. Com base no gráfico anterior, faça um painel em função da variável category, coloque a cor e preenchimento em função da mesma variável. Dica: facet_wrap. Com base no gráfico anterior, altere a ordem dos fatores das categorias, deixando Economics, Literature, Chemistry nas primeiras posições. Dica: fct_relevel. Calcule os 20 países com maior número de ganhadores com base na variável birth_country e faça um gráfico de barras. Dicas: tally, top_n, coord_flip. Com base no gráfico anterior, ordene as barras em função do numero de ganhadores. Dica: fct_reorder. "],
["joins.html", "Joins Exercícios", " Joins Estamos juntando dados de tabelas o tempo todo. Por diversos motivos parte das informações estão em uma tabela e parte estão em outra e precisamos parear esses dados para seguir com a análise. No Excel essa movimentação é feita pela função PROCV(), só que de maneira mais limitada. O pacote dplyr fornece uma família de funções para trabalhar com ‘joins’ no R. Vamos ver como as principais funcionam e como podemos aplicar nas nossas análises. Primeiro, temos que ter claro que iremos fazer a operação com duas tabelas e deixar claro quem é a tabela 1 (esquerda) e a tabela 2 (direita). A tabela 1 normalmente é nossa referencia e a partir dela iremos buscar algumas ou todas informações da tabela 2 a partir de pontos em comum. Veja no esquema abaixo as 4 principais que envolvem ‘joins’. library(tidyverse) set.seed(12345) x &lt;- tibble( chave = LETTERS[c(1:3, 5)], valor1 = sample(1:10, 4) ) y &lt;- tibble( chave = LETTERS[c(1:4)], valor2 = sample(1:10, 4), valor3 = sample(20:30, 4) ) Com base na tabela x, traga os valores da tabela y que correspondam com as chaves que existem na tabela x. Notem que a tabela 1 é o objeto x e eu quero ele como referencia. left_join(x, y, by = &quot;chave&quot;) Mas se eu quiser utilizar a tabela do objeto y como referência, ou eu mudo os objetos de posição na função ou utilizo a função right_join. right_join(x, y, by = &quot;chave&quot;) Agora, considerando apenas o que tem em comum nas duas tabelas e depois o juntando todas as possibilidades. inner_join(x, y) full_join(x, y) Vimos até agora os ‘joins’ que movimentam colunas de uma tabela para outra, mas há os ‘joins’ que servem para filtrar linhas na tabela de referencia e não movimentam informações entre as tabelas. O semi_join mantém os registros com base na coluna chave que existem nas duas tabelas. Já o anti_join mantém o registro que existe na tabela 1, mas não na tabela 2. semi_join(x, y) anti_join(x, y) Exercícios Carregue o pacote gapminder aplique a função glimpse na objeto gapminder que pertence ao respectivo pacote. #&gt; Observations: 1,704 #&gt; Variables: 6 #&gt; $ country &lt;fct&gt; Afghanistan, Afghanistan, Afghanistan, Afghanistan, ... #&gt; $ continent &lt;fct&gt; Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia... #&gt; $ year &lt;int&gt; 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992... #&gt; $ lifeExp &lt;dbl&gt; 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.8... #&gt; $ pop &lt;int&gt; 8425333, 9240934, 10267083, 11537966, 13079460, 1488... #&gt; $ gdpPercap &lt;dbl&gt; 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 78... Importe o arquivo continents.xlsx e mostre seu conteúdo na tela. #&gt; # A tibble: 6 x 4 #&gt; continent area_km2 population percent_total_pop #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Africa 30370000 1022234000 15 #&gt; 2 Americas 42330000 934611000 14 #&gt; 3 Antarctica 13720000 4490 0 #&gt; 4 Asia 43820000 4164252000 60 #&gt; 5 Europe 10180000 738199000 11 #&gt; 6 Oceania 9008500 29127000 0.4 Faça um join entre a tabela gapminder e continents, onde gapminder será a tabela de referência. Salve essa operação em um objeto chamado gap_cont. #&gt; # A tibble: 1,704 x 9 #&gt; country continent year lifeExp pop gdpPercap area_km2 population #&gt; &lt;fct&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Afghan~ Asia 1952 28.8 8.43e6 779. 43820000 4164252000 #&gt; 2 Afghan~ Asia 1957 30.3 9.24e6 821. 43820000 4164252000 #&gt; 3 Afghan~ Asia 1962 32.0 1.03e7 853. 43820000 4164252000 #&gt; 4 Afghan~ Asia 1967 34.0 1.15e7 836. 43820000 4164252000 #&gt; 5 Afghan~ Asia 1972 36.1 1.31e7 740. 43820000 4164252000 #&gt; 6 Afghan~ Asia 1977 38.4 1.49e7 786. 43820000 4164252000 #&gt; 7 Afghan~ Asia 1982 39.9 1.29e7 978. 43820000 4164252000 #&gt; 8 Afghan~ Asia 1987 40.8 1.39e7 852. 43820000 4164252000 #&gt; 9 Afghan~ Asia 1992 41.7 1.63e7 649. 43820000 4164252000 #&gt; 10 Afghan~ Asia 1997 41.8 2.22e7 635. 43820000 4164252000 #&gt; # ... with 1,694 more rows, and 1 more variable: percent_total_pop &lt;dbl&gt; Com base no objeto gap_cont, filtre as informações do continente Antarctica. #&gt; # A tibble: 0 x 9 #&gt; # ... with 9 variables: country &lt;fct&gt;, continent &lt;chr&gt;, year &lt;int&gt;, #&gt; # lifeExp &lt;dbl&gt;, pop &lt;int&gt;, gdpPercap &lt;dbl&gt;, area_km2 &lt;dbl&gt;, #&gt; # population &lt;dbl&gt;, percent_total_pop &lt;dbl&gt; Faça um gráfico de dispersão com a area do continente e a renda per capta. Para isso, considere GDP = gdpPercap * pop como o PIB do país. Em seguida some o PIB em função do continente. A tabela continents informa a população do continente, divida o PIB do continente pela população do mesmo e salve e chame essa variável de per_cap, faça o gráfico proposto em seguida. Dicas: summarize, left_join, geom_text, nudge_y. "],
["tidydata.html", "Tidydata Conceito Exercícios", " Tidydata Conceito Se você pegar uma apostila ou livro de 10 anos atrás (e olhe que o R tem 23 anos) vai perceber que as análises tinham muitos mais passos apoiados em vetores (unidimensional) e listas (multidimensional). Com o tempo e principalmente por conta dos pacotes do tidyverse, a análise foi ficando cada vez mais amarrada aos data.frames, o que facilita a manipulação e deixa o código mais consistente. Hoje, toda manipulação de dados no R se baseia no conceito tidy data (material para leitura aqui e aqui) com data.frames. Por tidy data, entendemos que: Variáveis estão dispostas em colunas. Observações estão dispostas em linhas. Os valores atribuídos às variáveis em cada observação formam a tabela. Para exemplificar o conceito, vamos trabalhar com a base de IDH de municípios do estado de São Paulo. idh &lt;- read_excel(&quot;input/idh_1991_2010.xlsx&quot;) idh Neste dataset, temos uma variável de tempo chamada decada e outras variáveis que indicam o fator de desenvolvimento longevidade, educacao, renda para cada município cod_municipio. Se entendermos que cada um desses fatores de desenvolvimento é uma variável independente, está tudo certo perante o conceito do tidy data. Mas se pensarmos bem, esses fatores também podem ser considerados níveis de uma variável idh, cuja média dos fatores retorna o IDH que conhecemos. Então, o formato que vamos dar aos nossos dados pode variar dependendo da pergunta que queremos responder. Um exemplo prático é tentarmos fazer um gráfico dos fatores de desenvolvimento ao longo do tempo para uma cidade específica. O ggplot2 assume que, se você for gerar uma legenda, ela tem que estar referenciada a uma variável. Nesse caso, temos 3 variáveis para gerar uma legenda, e isso não é legal para o ggplot2. idh %&gt;% filter(cod_municipio == 3501608) %&gt;% # Americana-SP ggplot(aes(x = decada)) + geom_line(aes(y = longevidade, color = &quot;longevidade&quot;)) + geom_line(aes(y = educacao, color = &quot;educacao&quot;)) + geom_line(aes(y = renda, color = &quot;renda&quot;)) Tivemos que fazer uma gambiarra porque para este gráfico, os dados precisam estar formatados de outra maneira. Vamos dar um talento nele e refazer o gráfico. idh_tidy &lt;- gather(idh, fator, idh, longevidade, educacao, renda) idh_tidy idh_tidy %&gt;% filter(cod_municipio == 3501608) %&gt;% ggplot(aes(x = decada, y = idh, color = fator)) + geom_line() De maneira geral, temos que fazer essas manipulações para encaixar os dados no formado que a função foi desenhada para trabalhar. E essa transposição é super fácil com o gather e com o spread. Um é o oposto do outro. No primeiro caso nós ‘tombamos’ as colunas para uma única variável. Para retornar ao formato original, é só usar o spread. idh_tidy %&gt;% spread(fator, idh) idh_tidy %&gt;% spread(decada, idh) idh_tidy %&gt;% ggplot(aes(x = decada, y = idh)) + geom_line(aes(group = cod_municipio), alpha = 0.1) + facet_wrap(~fator) + theme_bw() idh_tidy %&gt;% ggplot(aes(fator, idh, fill = fator)) + geom_violin() + facet_wrap(~decada, scales = &quot;free_x&quot;) + theme_bw() Exercícios Importe o arquivo base_vespa2.xlsx e use a função glimpse() para ver a estrutura da base. #&gt; Observations: 140 #&gt; Variables: 17 #&gt; $ Tratamento &lt;chr&gt; &quot;Actara d1&quot;, &quot;Actara d1&quot;, &quot;Actara d1&quot;, &quot;Actara d1&quot;... #&gt; $ Individuo &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,... #&gt; $ `1-Peciolo` &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... #&gt; $ `1-Nervura` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... #&gt; $ `1-Caule` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA... #&gt; $ `2-Peciolo` &lt;dbl&gt; 1, NA, NA, NA, NA, NA, 2, NA, NA, NA, NA, NA, NA, ... #&gt; $ `2-Nervura` &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... #&gt; $ `2-Caule` &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... #&gt; $ `3-Peciolo` &lt;dbl&gt; 1, NA, 1, NA, NA, NA, 7, NA, NA, NA, 1, NA, NA, NA... #&gt; $ `3-Nervura` &lt;dbl&gt; 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA,... #&gt; $ `3-Caule` &lt;dbl&gt; 2, NA, 1, NA, NA, NA, 3, NA, NA, NA, NA, NA, NA, N... #&gt; $ `4-Peciolo` &lt;dbl&gt; 2, NA, 2, NA, NA, NA, 8, NA, NA, NA, 1, NA, NA, NA... #&gt; $ `4-Nervura` &lt;dbl&gt; 1, NA, 1, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, ... #&gt; $ `4-Caule` &lt;dbl&gt; 2, NA, 1, NA, NA, NA, 4, NA, NA, NA, NA, NA, NA, N... #&gt; $ `5-Peciolo` &lt;dbl&gt; 6, NA, 2, NA, NA, NA, 15, NA, NA, NA, 4, NA, NA, N... #&gt; $ `5-Nervura` &lt;dbl&gt; 3, NA, 1, NA, NA, NA, 10, NA, NA, NA, NA, NA, NA, ... #&gt; $ `5-Caule` &lt;dbl&gt; 2, NA, 1, NA, NA, NA, 5, NA, NA, NA, 1, NA, NA, NA... Reformule a base de dados seguindo os conceitos do tidy data. #&gt; # A tibble: 2,100 x 5 #&gt; Tratamento Individuo Coleta Local Galhas #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Actara d1 1 1 Peciolo 1 #&gt; 2 Actara d1 2 1 Peciolo NA #&gt; 3 Actara d1 3 1 Peciolo NA #&gt; 4 Actara d1 4 1 Peciolo NA #&gt; 5 Actara d1 5 1 Peciolo NA #&gt; 6 Actara d1 6 1 Peciolo NA #&gt; 7 Actara d1 7 1 Peciolo NA #&gt; 8 Actara d1 8 1 Peciolo NA #&gt; 9 Actara d1 9 1 Peciolo NA #&gt; 10 Actara d1 10 1 Peciolo NA #&gt; # ... with 2,090 more rows Importe o arquivo voto_presidente_2018.csv e salve em um objeto chamado voto. Use a função glimpse() para ver a estrutura da base. #&gt; Observations: 15 #&gt; Variables: 31 #&gt; $ ANO_ELEICAO &lt;dbl&gt; 2018, 2018, 2018, 2018, 2018, 2018, 2018, 201... #&gt; $ NUM_TURNO &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1 #&gt; $ NUMERO_CANDIDATO &lt;dbl&gt; 12, 13, 15, 16, 17, 18, 19, 27, 30, 45, 50, 5... #&gt; $ DESCRICAO_CARGO &lt;chr&gt; &quot;PRESIDENTE&quot;, &quot;PRESIDENTE&quot;, &quot;PRESIDENTE&quot;, &quot;PR... #&gt; $ AC &lt;dbl&gt; 21809, 78170, 6458, 80, 262508, 10557, 1531, ... #&gt; $ AL &lt;dbl&gt; 155457, 687247, 43895, 744, 528355, 15843, 51... #&gt; $ AM &lt;dbl&gt; 138997, 746998, 23420, 835, 805902, 29196, 85... #&gt; $ AP &lt;dbl&gt; 50553, 134287, 5611, 560, 166935, 9008, 1435,... #&gt; $ BA &lt;dbl&gt; 693273, 4441955, 33109, 2240, 1725140, 61481,... #&gt; $ CE &lt;dbl&gt; 1998597, 1616492, 27902, 1563, 1061075, 18071... #&gt; $ DF &lt;dbl&gt; 266272, 190508, 26939, 908, 936494, 32115, 11... #&gt; $ ES &lt;dbl&gt; 195553, 495868, 22232, 711, 1122131, 26529, 1... #&gt; $ GO &lt;dbl&gt; 280864, 713535, 90778, 1011, 1868686, 28783, ... #&gt; $ MA &lt;dbl&gt; 282472, 2062638, 52214, 2842, 817531, 23635, ... #&gt; $ MG &lt;dbl&gt; 1278819, 3037957, 111999, 6160, 5308047, 9741... #&gt; $ MS &lt;dbl&gt; 112296, 333407, 18154, 623, 769116, 12279, 12... #&gt; $ MT &lt;dbl&gt; 91344, 404604, 16735, 610, 981119, 12487, 130... #&gt; $ PA &lt;dbl&gt; 415593, 1714822, 100724, 2391, 1499294, 53682... #&gt; $ PB &lt;dbl&gt; 362775, 984398, 21900, 819, 677718, 12508, 60... #&gt; $ PE &lt;dbl&gt; 640860, 2309104, 32088, 2021, 1444685, 46524,... #&gt; $ PI &lt;dbl&gt; 211240, 1172147, 16761, 850, 346944, 13313, 5... #&gt; $ PR &lt;dbl&gt; 510541, 1210974, 73795, 2246, 3496448, 47335,... #&gt; $ RJ &lt;dbl&gt; 1300292, 1255425, 77333, 6005, 5107735, 13079... #&gt; $ RN &lt;dbl&gt; 399766, 738165, 11480, 1034, 541448, 10690, 5... #&gt; $ RO &lt;dbl&gt; 52118, 176107, 12829, 464, 538311, 7351, 8738... #&gt; $ RR &lt;dbl&gt; 14838, 49406, 3426, 146, 174306, 4098, 1472, ... #&gt; $ RS &lt;dbl&gt; 724429, 1453291, 124713, 3086, 3353623, 50007... #&gt; $ SC &lt;dbl&gt; 264312, 598578, 51670, 1686, 2603665, 25813, ... #&gt; $ SE &lt;dbl&gt; 148526, 571234, 8784, 3093, 310310, 15829, 44... #&gt; $ SP &lt;dbl&gt; 2650440, 3833982, 267725, 12434, 12378012, 26... #&gt; $ TO &lt;dbl&gt; 54262, 311212, 5324, 251, 337782, 7229, 2471,... Reformule o objeto voto seguindo os conceitos do tidy data. Salve a nova base em um objeto chamado voto_tidy. #&gt; # A tibble: 405 x 6 #&gt; ANO_ELEICAO NUM_TURNO NUMERO_CANDIDATO DESCRICAO_CARGO estado voto #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 2018 1 12 PRESIDENTE AC 21809 #&gt; 2 2018 1 13 PRESIDENTE AC 78170 #&gt; 3 2018 1 15 PRESIDENTE AC 6458 #&gt; 4 2018 1 16 PRESIDENTE AC 80 #&gt; 5 2018 1 17 PRESIDENTE AC 262508 #&gt; 6 2018 1 18 PRESIDENTE AC 10557 #&gt; 7 2018 1 19 PRESIDENTE AC 1531 #&gt; 8 2018 1 27 PRESIDENTE AC 241 #&gt; 9 2018 1 30 PRESIDENTE AC 1990 #&gt; 10 2018 1 45 PRESIDENTE AC 33115 #&gt; # ... with 395 more rows Crie uma variável rank para indicar a posição referente ao número de votos apurados de cada candidato dentro de cada estado. Ordene a variável NUMERO_CANDIDATO em função do numero de votos. Faça um heatmap com o resultado do rank. Dicas: group_by, row_number, fct_reorder, geom_tile. "],
["iteracao.html", "Iteração For loop Programação funcional Exercícios", " Iteração Existe uma máxima muito interessante entre programadores que diz: Don’t Repeat Yourself (DRY) Humanos são extremamente distraídos e cometem muitos erros quando fazer operações repetitivas. Quando estamos programando, não é diferente. As vezes parece mais fácil copiar e colar uma estrutura de código para alterar apenas um detalhe e ter o resultado que se espera. Mas quando o numero de repetições começa a aumentar a chance de fazermos algo errado cresce junto. No R, esse tipo de problema é resolvido de duas formas: com funções customizadas ou com loops. Nesse modulo vamos falar apenas de loops, mas com certeza ele já vai resolver muitos dos nossos problemas de repetição. Como exemplo para esse tema, temos um planilha com os dados separados em abas e temos de juntar todos eles para iniciar a análise. Os dados estão na planilha base_vespa1.xlsx e em seguida vamos fazer essa junção de 3 formas diferentes. library(tidyverse) library(readxl) library(broom) aba1 &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = 1) aba2 &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = 2) aba3 &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = 3) aba4 &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = 4) aba5 &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = 5) base_mobral &lt;- bind_rows(aba1, aba2, aba3, aba4, aba5) base_mobral base_loop_out &lt;- list() for (i in 1:5) { base_loop_out[[i]] &lt;- read_excel(&quot;input/base_vespa1.xlsx&quot;, sheet = i) } base_loop &lt;- bind_rows(base_loop_out) base_loop base_purrr &lt;- excel_sheets(&quot;input/base_vespa1.xlsx&quot;) %&gt;% map_df(read_excel, path = &quot;input/base_vespa1.xlsx&quot;) base_purrr Estes 3 métodos exemplificam bastante a relação entre domínio da programação e quantidade de trabalhado apenas pelo computador. No primeiro exemplo tivermos que repetir várias vezes a estrutura do código para poder chegar no resultado esperado. No segundo, já fomos um pouco mais diretos e deixamos o trabalho repetitivo para o computador. Imagina se tivéssemos 30 abas para juntar? E se fossem 500 arquivos? O terceiro exemplo é um passo além de loops e em linguagem de programação chama-se functional programming, onde funções são usadas para realizar as operações que envolvem loops. For loop Loops são bem comuns em linguagem de programação e nos ajudam muito nas tarefas repetitivas. Eles são compostos de 3 partes: O output, estrutura que será populada em cada iteração. Pode ser um vetor, lista ou data frame. Uma sequência, o universo de possibilidades que será executada em cada iteração ou passo. É comum chamarmos de i, mas pode ser qualquer denominação e no código é como se fosse um objeto que a cada iteração muda de conteúdo. O corpo, parte que faz o calculo ou operação envolvendo os passos i e guardando no output. Retomando o loop que fizemos para ler as abas, temos os 3 componentes bem claros. Vamos rescreve os loop seguindo algumas boas práticas. arquivo &lt;- &quot;input/base_vespa1.xlsx&quot; base_loop_out &lt;- vector(&quot;list&quot;, length = length(excel_sheets(arquivo))) for (i in seq_along(base_loop_out)) { base_loop_out[[i]] &lt;- read_excel(arquivo, sheet = i) } base_loop &lt;- bind_rows(base_loop_out) base_loop Programação funcional A outra forma de realizar tarefas repetitivas em R é utilizando funções que foram desenhadas para trabalhar com iteração. O pacote do tidyverse que reúne estas funções chame-se purrr. A ideia das funções do purrr é desenhar as iterações sobre vetores, listas ou linhas de um data frame. map(c(1, 2, 3, 4), rnorm) map_dbl(mtcars, mean) map_int(iris, function(x) length(unique(x))) map_int(iris, ~ length(unique(.))) O pacote tem várias funções e você pode ler sobre elas com mais calma depois. Neste bloco, utilizar a programação funcional para ajustar regressões especificas para um determinado grupo e sempre mantendo tudo amarado a data frames. Esse é uma concepção de programação bastante nova no R, onde coloca o data frame como esqueleto principal da análise e aplicando todas as etapas dentro dele. inv &lt;- read_excel(&quot;input/TUME_134_2016.xlsx&quot;) inv Nosso objetivo é ajustar um modelo hipsométrico (diâmetro-altura) para cada espécie e em seguida predizer as alturas das árvores. O gráfico a seguir mostra a relação que teríamos se fosse ajustado apenas um modelo para todas as espécies. ggplot(inv, aes(CAP_cm, H_m)) + geom_point(alpha=0.4) + geom_smooth(method=&quot;lm&quot;) + theme_bw() Mas na prática, a relação diâmetro-altura é diferente entre as espécies, como pode ser notado logo abaixo. Talvez fique mais evidente a diferença observando os coeficientes dos modelos que serão ajustados a seguir. ggplot(inv, aes(CAP_cm, H_m)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + facet_wrap(~Esp) Para entendermos o processo, vamos ajustar a regressão para algumas espécies. O comando lm() utiliza a notação em formula para especificar o modelo. Lê-se H_m em função de CAP_cm, sendo o ~ responsável por determinar as variáveis dependentes e independentes. O pacote broom tem algumas funções que facilitam a extração das informações do modelo ajustado. Iremos utilizar a função glance para pegar as estatísticas gerais do modelo e a função tidy para acessar os coeficientes e significâncias. m1 &lt;- lm(H_m ~ CAP_cm, data = filter(inv, Esp == &quot;E_citriodora&quot;)) glance(m1) tidy(m1) m2 &lt;- lm(H_m ~ CAP_cm, data = filter(inv, Esp == &quot;E_maculata&quot;)) glance(m2) tidy(m2) A primeira etapa é entender que um data.frame pode conter vários tipos de elementos, como números, caracteres, listas e também outros data.frames. Para isso utilizaremos a função nest() do pacote tidyr e aninharemos os dados em função das espécies. inv_nest &lt;- inv %&gt;% group_by(Esp) %&gt;% nest() inv_nest Agora podemos ajustar um modelo de regressão para cada espécie utilizando a função map, do pacote purrr. dados_modl &lt;- inv_nest %&gt;% mutate( ajuste = map(data, ~lm(H_m ~ CAP_cm, data = .)), resumo = map(ajuste, glance), coef = map(ajuste, tidy), resid = map(ajuste, augment) ) dados_modl Da mesma forma que aninhamos os dados por espécie, podemos retorná-los para o formato original, mas agora mostrando apenas as informações que realmente interessam. dados_modl %&gt;% select(Esp, resumo) %&gt;% unnest(resumo) dados_modl %&gt;% select(Esp, coef ) %&gt;% unnest(coef) Após o ajuste do modelo, temos de predizer as alturas. Por fim, temos de volta um data.frame com as alturas preditas. dados_pred &lt;- dados_modl %&gt;% mutate( hpred = map2(ajuste, data, predict) ) %&gt;% select(Esp, data, hpred) %&gt;% unnest(hpred, data) dados_pred Para visualizar o resultado da regressão, podemos colocar no gráfico a comparação entre valores medidos e preditos. dados_pred %&gt;% ggplot(aes(CAP_cm)) + geom_point(aes(y = H_m), color = &quot;cadetblue&quot;) + geom_point(aes(y = hpred), color = &quot;red&quot;) + facet_wrap(~Esp) + theme_bw() Exercícios A partir do data frame gapminder crie o objeto gap_nested com os dados aninhados em função de continent e country. Dica: nest. #&gt; # A tibble: 142 x 3 #&gt; continent country data #&gt; &lt;fct&gt; &lt;fct&gt; &lt;list&gt; #&gt; 1 Asia Afghanistan &lt;tibble [12 x 4]&gt; #&gt; 2 Europe Albania &lt;tibble [12 x 4]&gt; #&gt; 3 Africa Algeria &lt;tibble [12 x 4]&gt; #&gt; 4 Africa Angola &lt;tibble [12 x 4]&gt; #&gt; 5 Americas Argentina &lt;tibble [12 x 4]&gt; #&gt; 6 Oceania Australia &lt;tibble [12 x 4]&gt; #&gt; 7 Europe Austria &lt;tibble [12 x 4]&gt; #&gt; 8 Asia Bahrain &lt;tibble [12 x 4]&gt; #&gt; 9 Asia Bangladesh &lt;tibble [12 x 4]&gt; #&gt; 10 Europe Belgium &lt;tibble [12 x 4]&gt; #&gt; # ... with 132 more rows Com o objeto gap_nested ajuste um modelo linear com a formula lifeExp ~ year e calcule as estatísticas do modelos ajustados Dica: map, lm, tidy. #&gt; # A tibble: 142 x 5 #&gt; continent country data fit tidy #&gt; &lt;fct&gt; &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; #&gt; 1 Asia Afghanistan &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 2 Europe Albania &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 3 Africa Algeria &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 4 Africa Angola &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 5 Americas Argentina &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 6 Oceania Australia &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 7 Europe Austria &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 8 Asia Bahrain &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 9 Asia Bangladesh &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; 10 Europe Belgium &lt;tibble [12 x 4]&gt; &lt;lm&gt; &lt;tibble [2 x 5]&gt; #&gt; # ... with 132 more rows Salve no objeto gap_coef o desaninhe os dados. Dica: unnest. #&gt; # A tibble: 284 x 7 #&gt; continent country term estimate std.error statistic p.value #&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Asia Afghanistan (Intercept) -508. 40.5 -12.5 1.93e- 7 #&gt; 2 Asia Afghanistan year 0.275 0.0205 13.5 9.84e- 8 #&gt; 3 Europe Albania (Intercept) -594. 65.7 -9.05 3.94e- 6 #&gt; 4 Europe Albania year 0.335 0.0332 10.1 1.46e- 6 #&gt; 5 Africa Algeria (Intercept) -1068. 43.8 -24.4 3.07e-10 #&gt; 6 Africa Algeria year 0.569 0.0221 25.7 1.81e-10 #&gt; 7 Africa Angola (Intercept) -377. 46.6 -8.08 1.08e- 5 #&gt; 8 Africa Angola year 0.209 0.0235 8.90 4.59e- 6 #&gt; 9 Americas Argentina (Intercept) -390. 9.68 -40.3 2.14e-12 #&gt; 10 Americas Argentina year 0.232 0.00489 47.4 4.22e-13 #&gt; # ... with 274 more rows Faça um gráfico mostrando a variação dos parâmetros ajustados por Continente. Dicas: geom_jitter, facet_wrap(…, scales = “free_y”). Importe o arquivo woman.xls e salve num objeto chamado woman. Dicas: ?read_excel, skip. #&gt; Observations: 264 #&gt; Variables: 63 #&gt; $ `Country Name` &lt;chr&gt; &quot;Aruba&quot;, &quot;Afghanistan&quot;, &quot;Angola&quot;, &quot;Albania&quot;, ... #&gt; $ `Country Code` &lt;chr&gt; &quot;ABW&quot;, &quot;AFG&quot;, &quot;AGO&quot;, &quot;ALB&quot;, &quot;AND&quot;, &quot;ARB&quot;, &quot;AR... #&gt; $ `Indicator Name` &lt;chr&gt; &quot;Proportion of seats held by women in nationa... #&gt; $ `Indicator Code` &lt;chr&gt; &quot;SG.GEN.PARL.ZS&quot;, &quot;SG.GEN.PARL.ZS&quot;, &quot;SG.GEN.P... #&gt; $ `1960` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1961` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1962` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1963` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1964` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1965` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1966` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1967` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1968` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1969` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1970` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1971` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1972` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1973` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1974` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1975` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1976` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1977` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1978` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1979` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1980` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1981` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1982` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1983` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1984` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1985` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1986` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1987` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1988` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1989` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1990` &lt;dbl&gt; NA, 3.700000, 14.500000, 28.800000, NA, 3.891... #&gt; $ `1991` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1992` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1993` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1994` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1995` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1996` &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N... #&gt; $ `1997` &lt;dbl&gt; NA, NA, 9.500000, NA, 7.100000, 3.757835, 0.0... #&gt; $ `1998` &lt;dbl&gt; NA, NA, 15.500000, NA, 7.100000, 3.474235, 0.... #&gt; $ `1999` &lt;dbl&gt; NA, NA, 15.500000, 5.200000, 7.100000, 3.6234... #&gt; $ `2000` &lt;dbl&gt; NA, NA, 15.500000, 5.200000, 7.100000, 3.7681... #&gt; $ `2001` &lt;dbl&gt; NA, NA, 15.500000, 5.700000, 14.300000, 4.610... #&gt; $ `2002` &lt;dbl&gt; NA, NA, 15.500000, 5.700000, 14.300000, 6.132... #&gt; $ `2003` &lt;dbl&gt; NA, NA, 15.500000, 5.700000, 14.300000, 6.043... #&gt; $ `2004` &lt;dbl&gt; NA, NA, 15.000000, 6.400000, 14.300000, 6.702... #&gt; $ `2005` &lt;dbl&gt; NA, 27.300000, 15.000000, 7.100000, 28.600000... #&gt; $ `2006` &lt;dbl&gt; NA, 27.300000, 15.000000, 7.100000, 28.600000... #&gt; $ `2007` &lt;dbl&gt; NA, 27.700000, 15.000000, 7.100000, 28.600000... #&gt; $ `2008` &lt;dbl&gt; NA, 27.700000, 37.300000, 7.100000, 25.000000... #&gt; $ `2009` &lt;dbl&gt; NA, 27.300000, 38.600000, 16.400000, 35.70000... #&gt; $ `2010` &lt;dbl&gt; NA, 27.70000, 38.60000, 16.40000, 35.70000, 1... #&gt; $ `2011` &lt;dbl&gt; NA, 27.70000, 38.20000, 15.70000, 50.00000, 1... #&gt; $ `2012` &lt;dbl&gt; NA, 27.70000, 34.10000, 15.70000, 50.00000, 1... #&gt; $ `2013` &lt;dbl&gt; NA, 27.70000, 34.10000, 17.90000, 50.00000, 1... #&gt; $ `2014` &lt;dbl&gt; NA, 27.70000, 36.80000, 20.00000, 50.00000, 1... #&gt; $ `2015` &lt;dbl&gt; NA, 27.70000, 36.80000, 20.70000, 39.30000, 1... #&gt; $ `2016` &lt;dbl&gt; NA, 27.70000, 36.80000, 22.90000, 32.10000, 1... #&gt; $ `2017` &lt;dbl&gt; NA, 27.70000, 38.20000, 27.90000, 32.10000, 1... #&gt; $ `2018` &lt;dbl&gt; NA, 27.70000, 30.50000, 27.90000, 32.10000, 1... Reformate a tabela seguindo os conceitos do tidy data. #&gt; # A tibble: 15,576 x 6 #&gt; `Country Name` `Country Code` `Indicator Name` `Indicator Code` ano #&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; #&gt; 1 Aruba ABW Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 2 Afghanistan AFG Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 3 Angola AGO Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 4 Albania ALB Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 5 Andorra AND Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 6 Arab World ARB Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 7 United Arab E~ ARE Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 8 Argentina ARG Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 9 Armenia ARM Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; 10 American Samoa ASM Proportion of s~ SG.GEN.PARL.ZS 1960 #&gt; # ... with 15,566 more rows, and 1 more variable: percentual &lt;dbl&gt; Em que ano começam os registros dessa base de dados? Neste ano, qual o país com maior percentual de mulheres? Dica: as.numeric, !, is.na. #&gt; # A tibble: 1 x 3 #&gt; `Country Name` ano percentual #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Sweden 1990 38.4 Quais os 10 países com maior percentual de mulheres no parlamento em 2018? Dica: as.numeric, top_n, arrange. #&gt; # A tibble: 10 x 2 #&gt; `Country Name` percentual #&gt; &lt;chr&gt; &lt;dbl&gt; #&gt; 1 Rwanda 61.3 #&gt; 2 Cuba 53.2 #&gt; 3 Bolivia 53.1 #&gt; 4 Mexico 48.2 #&gt; 5 Grenada 46.7 #&gt; 6 Namibia 46.2 #&gt; 7 Sweden 46.1 #&gt; 8 Nicaragua 45.7 #&gt; 9 Costa Rica 45.6 #&gt; 10 South Africa 42.3 Faça um gráfico de linha mostrando a evolução do percentual médio de mulheres no mundo desde 1997 Faça o gráfico anterior somente com dados do Brasil Consegue juntar estes dois gráficos em um só, com duas linhas? Dica: ifelse. "]
]
